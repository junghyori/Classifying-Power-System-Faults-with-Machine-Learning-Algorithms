# Classifying-Power-System-Faults-with-Machine-Learning-Algorithms

-----------------------------------------------------------------------------------
Contents:
    - Folder structure
    - How to use this folder
    - Folder/file descriptions
    - Dependencies

-----------------------------------------------------------------------------------
Folder structure:

This folder contains 17 files, of the formats .ipynb, .csv, .py and .txt and is structured as follows. The number beside each file name is referred back to in the descriptions of each file given in the 'file description' 

\fomlads_code_archive_7
    \downloaded_datasets (0)
        power_1.csv
        power_2.csv
        power_3.csv
        power_4.csv
        power_5.csv
    power_clean.csv (1)
    train_filter_fixed.csv (2)
    test_filter_fixed.csv (3)
    functions.py (4)
    data_processing.ipynb (5)
    grid_search.ipynb (6)
    svm_model.ipynb (7)
    mlp_model.ipynb (8)
    randomforest_model.ipynb (9)
    logisticregression_model.ipynb (10)
    all_models.ipynb (11)
    README.txt
    
-----------------------------------------------------------------------------------
How to use this folder (to reproduce results discussed in the accompanying report):


There are 7 notebooks, which are all implementations of experiments discussed in the research, including data processing, model selection, model fit/prediction/evaluation. To replicate results discussed in the research, it will suffice to run the notebooks with necessary dependencies installed. There is extensive in-line documentation in these notebooks and function documentation in the functions.py file, should the user wish to alter inputs or outputs. The run times of each notebook is detailed both in this file and at the start of notebooks themselves.

-----------------------------------------------------------------------------------
Folder/file descriptions:

What follows is a high-level description of what the each file, and also the downloaded_datasets folder, contains; whether content/functions are imported from other files; what visual outputs should be generated (used in the accompanying report).

    (0)   Folder name: downloaded_datasets
          Folder contents: This folder contains 5 csv files, which are downloaded directly from 
          (http://www.ece.uah.edu/~thm0009/icsdatasets/multiclass.7z or by clicking on the 'Multiclass' link on this page 
          https://sites.google.com/a/uah.edu/tommy-morris-uah/ics-data-sets?authuser=0) in ARFF format and converted to csv 
          through the ARFF viewer of the application weka-3.8.6.

    (1)   File name: power_clean.csv
          File type: CSV
          File contents: This is the key dataset used in the research.
        
    (2&3) File names: train_filter_seed.csv, test_filter_seed.csv
          File types: csv
          File contents: These files are both arrays of Booleans generated by the train_and_test_filter functions from 
          the functions file. As this function uses randomness (np.random.choice), these files contain fixed outputs that can be 
          used to exactly reproduce results of experiments referenced in the accompanying report.
        
    (4)   File name: functions.py
          File type: Python
          File contents: This file contains five functions for various data processing and modelling steps. There is detailed 
          documentations for these five functions, which are used extensively in the following Jupyter notebook files. The 
          train_and_test_filter function imports the Booleans from files (2&3) as numpy arrays if the parameter use_fixed_filter 
          is set to True, which is also the default. If this parameter is set to False, new (random) arrays are generated.
          
    (5)   File name: data_processing.ipynb
          File type: Jupyter notebook
          Run time of all cells in notebook: <1 min
          File contents: This file imports data from the 5 csv files in the subfolder with name 'downloaded_datasets'. The code
          demonstrates how five separate datafiles are compiled into one and certain lines of data are removed. The resulting 
          processed data is saved to a csv file, which is the same as (1). If every cell in the notebook is run, the file 
          'power_clean_donotuse.csv' is both created and removed, as the notebook is designed to 
          be purely demonstrative of the process of obtaining 'power_clean.csv'
    
    (6)   File name: grid_search.ipynb
          File type: Jupyter notebook
          
          WARNING! Run time of all cells in notebook: ~1 hour. It is not recommended that this notebook is run with the code as 
          is as the run time is long. The fold filters will also be randomly generated each time. For testing of the code, 
          altering the num_folds parameter in the fold_train_test_filter function and the C_range, gamma_range variables in the 
          fourth code block can be changed to reduce run time. For more details see function documentation in functions.py.
          
          File contents: This file imports functions from (4), data from (1), (2&3) and performs a grid search with cross 
          validation and 3 folds and given C and gamma hyperparameter ranges (3 values for each) for an SVM model with (default) 
          rbf kernel. Documentation of the relevant functions are in functions.py. The output is visualised as a barchart of f1 
          scores for all 9 hyperparameter combinations.
    
    (7)   File name: SVM Model.ipynb
          File type: Jupyter notebook
          Run time of all cells in notebook: 3-4 min
          File contents: This file imports functions from (4), data from (1), (2&3) to implement the SVC model imported from 
          sklearn.svm with specified C and gamma hyperparameters and (default) rbf kernel. The fit and predict functionality of 
          sklearn is used and the output is the f1 scores across classes as well as the macro f1 score visualised in a chart.
          
    (8)   File name: MLP Model.ipynb
          File type: Jupyter notebook
          Run time of all cells in notebook: <1 min
          File contents: This file imports functions from (4), data from (1), (2&3) to implement the MLPClassifier model imported 
          from sklearn.neural_network with specified hyperparameters: hidden layer sizes, maximum # of iterations and activation
          function. The fit and predict functionality of sklearn is used and the output is the f1 scores across classes as 
          well as the macro f1 score visualised in a chart.
          
    (9)   File name: RandomForest Model.ipynb
          File type: Jupyter notebook
          Run time of all cells in notebook: <1 min
          File contents: This file imports functions from (4), data from (1), (2&3) to implement the RandomForestClassifier model 
          imported from sklearn with specified hyperparameters: # of trees in forest, maximum depth of the tree. The fit and 
          predict functionality of sklearn is used and the output is the f1 scores across classes as well as the macro f1 score 
          visualised in a chart. A classification report from sklearn for the model is also visualised as a heatmap using 
          seaborn.
      
     (10) File name: LogisticRegression Model.ipynb
          File type: Jupyter notebook
          Run time of all cells in notebook: 5 min
          File contents: This file imports functions from (4), data from (1), (2&3) to implement the LogisticRegression model 
          imported from sklearn.linear_model with specified hyperparameters: multi class as multinomial, to minimise multinomial 
          loss fit, solver and maximum # of iterations. The fit and predict functionality of sklearn is used and the output is 
          the f1 scores across classes as well as the macro f1 score visualised in a chart.
          
     (11) File name: all_models.ipynb
          File type: Jupyter notebook
          Run time of all cells in notebook: 8 min
          File contents: This file imports functions from (4), data from (1), (2&3) to implement all models and output 
          all results from files (7)-(10). The F1 scores for each class for each model are also visualised on the same plot, as 
          well as the macro F1 average scores for each model on a bar chart.
          
-----------------------------------------------------------------------------------
Dependencies:
    - python
    - numpy
    - pandas
    - sklearn
    - seaborn
    - os
